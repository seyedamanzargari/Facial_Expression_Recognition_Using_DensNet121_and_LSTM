{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0n3nEcYt5WCZ"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "from time import time\n",
        "import sklearn\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import *\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.densenet import DenseNet121\n",
        "from tensorflow.keras.applications.densenet import preprocess_input\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GoPITRGRb1Z_"
      },
      "outputs": [],
      "source": [
        "seed_constant = 27\n",
        "np.random.seed(seed_constant)\n",
        "random.seed(seed_constant)\n",
        "tf.random.set_seed(seed_constant)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5k3PrslC49ER"
      },
      "outputs": [],
      "source": [
        "model = DenseNet121()\n",
        "feature_extractor_model = tf.keras.Model(inputs=model.inputs, outputs=model.layers[-2].output)\n",
        "\n",
        "video_length = 70\n",
        "# read directory of classes. in each class read video frames. extract features from each frame using DenseNet121\n",
        "def read_video_frames(video_dir, classes_names):\n",
        "    video_frames = []\n",
        "    classes = []\n",
        "    for idx, class_name in enumerate(classes_names):\n",
        "        print('\\n', class_name)\n",
        "        class_dir = os.path.join(video_dir, class_name)\n",
        "\n",
        "        for video_name in tqdm(os.listdir(class_dir)):\n",
        "            cap = cv2.VideoCapture(os.path.join(class_dir, video_name))\n",
        "            frames = []\n",
        "\n",
        "            for i in range(video_length):\n",
        "                ret, frame = cap.read()\n",
        "                if ret == False:\n",
        "                  break\n",
        "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "                frame = cv2.resize(frame, (224, 224))\n",
        "                frames.append(frame)\n",
        "            cap.release()\n",
        "            \n",
        "            if len(frames) == video_length:\n",
        "              try:\n",
        "                frames = np.array(frames)\n",
        "                frames = preprocess_input(frames)\n",
        "                frames = feature_extractor_model.predict(frames)\n",
        "                video_frames.append(frames)\n",
        "                classes.append(idx)\n",
        "              except:\n",
        "                pass \n",
        "\n",
        "    return np.array(video_frames), np.array(classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jfgvJFZp5PnH"
      },
      "outputs": [],
      "source": [
        "classes = [\"Anger\", \"Disgust\", 'Fear', 'Happiness', 'Neutral', 'Sadness', 'Surprise']\n",
        "\n",
        "video_frames, classesf = read_video_frames('path/to/dataset/train', classes)\n",
        "X_test_v, y_test_v = read_video_frames('path/to/dataset/validation', classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P0ZHZBl6CL8X"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(video_frames, classesf, test_size=0.2, random_state=42, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_metric(model_training_history, metric_name_1, metric_name_2, plot_name):\n",
        "\n",
        "    metric_value_1 = model_training_history.history[metric_name_1]\n",
        "    metric_value_2 = model_training_history.history[metric_name_2]\n",
        "    epochs = range(len(metric_value_1))\n",
        "    plt.plot(epochs, metric_value_1, 'blue', label = 'train')\n",
        "    plt.plot(epochs, metric_value_2, 'red', label = 'validation')\n",
        "    plt.title(str(plot_name))\n",
        "    plt.legend()"
      ],
      "metadata": {
        "id": "j2IP6T06p6PC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_lstm_model():\n",
        "  model = Sequential()\n",
        "  model.add(layers.LSTM(64, input_shape=(70, 1024), return_sequences=True))\n",
        "  model.add(layers.LSTM(32))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.Dense(len(classes), activation='softmax'))\n",
        "  return model"
      ],
      "metadata": {
        "id": "pMvOo2z7taoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_lstm_model()\n",
        "\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath='modelbest.h5',\n",
        "    monitor='val_loss',\n",
        "    verbose = 1,\n",
        "    save_best_only=True)\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
        "\n",
        "history = model.fit(video_frames2, to_categorical(classesf), epochs=100, batch_size=64, verbose=1, shuffle = True, validation_data=[X_test_v, to_categorical(y_test_v)], callbacks = [model_checkpoint_callback])"
      ],
      "metadata": {
        "id": "K6sJrVhzpli_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('modelbest.h5')\n",
        "test_results = model.evaluate(X_test_v, to_categorical(y_test_v), verbose=1)\n",
        "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]}%')\n",
        "print(f'Precision: {test_results[2]} - Recall: {test_results[3]}')\n",
        "print(f'F1-Score: {2 * (test_results[2] * test_results[3]) / (test_results[2] + test_results[3])}')"
      ],
      "metadata": {
        "id": "KU8kyp0ipra9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_metric(history, 'loss', 'val_loss', 'Total Loss vs Total Validation Loss')"
      ],
      "metadata": {
        "id": "c3_mq1whqDLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_metric(history, 'accuracy', 'val_accuracy', 'Total Accuracy vs Total Validation Accuracy')"
      ],
      "metadata": {
        "id": "uVhdhTMRqEda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_build():\n",
        "  model = get_lstm_model()\n",
        "  opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "  model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy', tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])\n",
        "  return model"
      ],
      "metadata": {
        "id": "3n8-ZoaqseIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def KFold_cross_val_test(X, Y, K=5, Report=True, shuffle=False, print_report=True, random_state=False):\n",
        "    if random_state:\n",
        "        cv = KFold(n_splits=K, shuffle=shuffle, random_state=random_state)\n",
        "    else:\n",
        "        cv = KFold(n_splits=K, shuffle=shuffle)    \n",
        "\n",
        "    avgacc = 0\n",
        "    avgf1 = 0\n",
        "    avgprecision = 0\n",
        "    avgrecall = 0\n",
        "    f = 0\n",
        "    report = []\n",
        "    ticf=time()\n",
        "    \n",
        "    for train_ix, test_ix in cv.split(X):\n",
        "        result={}\n",
        "        train_X, test_X = X[train_ix], X[test_ix]\n",
        "        train_y, Y_test = Y[train_ix], Y[test_ix]\n",
        "\n",
        "        tic = time()\n",
        "        model = model_build()\n",
        "        model_filename = f'classi{f}_model.h5'\n",
        "        callback_checkpoint = tf.keras.callbacks.ModelCheckpoint(model_filename, verbose=0, monitor='val_loss', save_best_only=True)\n",
        "        history = model.fit(train_X, train_y, validation_data=(test_X,Y_test), epochs=100 ,verbose=0, callbacks=[callback_checkpoint])\n",
        "        toc = time()\n",
        "\n",
        "        model.load_weights(model_filename)\n",
        "        Y_pred = model.predict(X_test_v)\n",
        "        y_test_v_cat = to_categorical(y_test_v)\n",
        "\n",
        "        eval = model.evaluate(X_test_v, to_categorical(y_test_v), verbose=0)\n",
        "        acc = eval[1]\n",
        "        recall = eval[2]\n",
        "        precision = eval[3]\n",
        "        f1_s = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "        result[\"Accuracy score\"] = acc\n",
        "        avgacc += result[\"Accuracy score\"]\n",
        "        result[\"confusion matrix\"] = sklearn.metrics.confusion_matrix(y_test_v_cat.argmax(axis=1), Y_pred.argmax(axis=1))\n",
        "        result[\"f1 score\"] = f1_s\n",
        "        avgf1 += result[\"f1 score\"]\n",
        "        result[\"precision score\"] = precision\n",
        "        avgprecision += result[\"precision score\"]\n",
        "        result[\"recall\"] = recall\n",
        "        avgrecall += result[\"recall\"]\n",
        "        result[\"Training time\"] = toc-tic\n",
        "        f = f+1\n",
        "        if print_report:\n",
        "            print(f\"\\n ======== fold {f} ========\")\n",
        "            print(f\"\\nAccuracy score : \", result[\"Accuracy score\"])\n",
        "            print(f\"\\nconfusion matrix : \\n\", result[\"confusion matrix\"])\n",
        "            print(f\"\\nf1 score : \", result[\"f1 score\"])\n",
        "            print(f\"\\nrecall : \", result[\"recall\"])\n",
        "            print(f\"\\nprecision score : \", result[\"precision score\"])\n",
        "            print(f\"\\nTraining Time: {result['Training time']:.3f} s\")\n",
        "            \n",
        "            plt.plot(history.history['accuracy'])\n",
        "            plt.plot(history.history['val_accuracy'])\n",
        "            plt.title('model accuracy')\n",
        "            plt.ylabel('accuracy')\n",
        "            plt.xlabel('epoch')\n",
        "            plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "            plt.show()\n",
        "            plt.plot(history.history['loss'])\n",
        "            plt.plot(history.history['val_loss'])\n",
        "            plt.title('model loss')\n",
        "            plt.ylabel('loss')\n",
        "            plt.xlabel('epoch')\n",
        "            plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "            plt.show()\n",
        "            print(f\"\\n---------------------------\\n\")\n",
        "\n",
        "        report.append(result)\n",
        "    tocf=time()    \n",
        "    total_acc = avgacc/K\n",
        "    total_f1 = avgf1/K\n",
        "    total_precision = avgprecision/K\n",
        "    total_recall = avgrecall/K\n",
        "\n",
        "    print(f'5-fold Accuracy: ', total_acc)\n",
        "    print(f'5-fold F1: ', total_f1)\n",
        "    print(f'5-fold Precision: ', total_precision)\n",
        "    print(f'5-fold Recall: ', total_recall)\n",
        "\n",
        "    if Report:\n",
        "        return total_acc, report\n",
        "    else:\n",
        "        return total_acc"
      ],
      "metadata": {
        "id": "5cppeLnOsDp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ac, re = KFold_cross_val_test(video_frames, to_categorical(classesf), shuffle=True, random_state=0)"
      ],
      "metadata": {
        "id": "D-UbOWA0sTVJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Video-based Facial Expression Recognition Using DensNet121 and LSTM.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}